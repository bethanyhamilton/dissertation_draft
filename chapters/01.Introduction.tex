\chapter{Introduction}


Meta-analysis is the statistical approach to quantitatively summarize the results of multiple studies through the calculation and combination of effect sizes. Beyond combining statistical results estimated as effect sizes from multiple studies, meta-analyses are also used to evaluate the degree of variability across studies and effect sizes and explain that variability by incorporating study and sample characteristics as moderators in meta-regression models. 

In the social sciences, the meta-analytic data structure often includes multiple effect sizes reported for individual studies that lead to potential within-study dependence in the effect sizes. Meta-regression models have been developed to model the complex error structure of these dependent effect sizes \autocite{vandennoortgate2013, hedges2010, viechtbauer2010a, sera2019, pustejovsky2022}. While there has been work on understanding the statistical power of such models to detect a non-null average effect size \autocite{vembye2023}, researchers still need to understand how these models perform to detect non-null moderating relations. Furthermore, prior approximations for the power of statistical tests of moderators in meta-regression have only been made for models that assume independent effects \autocite{hedges2004, jackson2017, valentine2010}, which does not apply in meta-analyses where primary studies contribute multiple related effect sizes. 

For meta-analysis, an a priori power analysis helps researchers determine whether the existing number of studies and effect sizes on a topic of interest for a meta-analysis is adequate to conduct a moderator analysis to explain the heterogeneity in the effect sizes \autocite{hedges2001}. Because a meta-analysis requires a substantial investment of time and money, applied researchers and potential funders need to determine whether the body of available research and data suffices to offer a valid evaluation of the associated meta-analytic research questions. Moderator analyses in meta-analysis are often conducted to evaluate a hypothesis that the magnitude of the effect size varies as a function of study design or population characteristics. If such tests were inadequately powered, it could lead to erroneous conclusions \autocite{hedges2004}. Furthermore, because moderator analyses require larger meta-analytic datasets \autocite{hedges2004}, it is crucial to understand how the estimates of statistical power to detect a moderator's effect may differ depending on the structure of the meta-analytic data and the model used for analysis. 

Extending the work done by \textcite{vembye2023}, this dissertation introduces a power approximation for the test of multiple contrasts of study-level categorical moderators assuming a correlated-and-hierarchical effects working model with robust variance estimation \autocite[e.\,g. CHE+RVE;][]{pustejovsky2022, hedges2010}. The CHE model accounts for the correlated structure of the effect size estimates and the multilevel structure of the effect sizes nested within primary studies. In this dissertation, I detail the derivations for the power approximations for the test for a moderator with two categories that only vary between studies and the test for a moderator with more than two categories. Furthermore, I validate the power approximation for multiple categories through a Monte Carlo simulation. The Monte Carlo simulation involves several design factors, including the number of categories of a study-level moderator, the number of studies in the meta-analytic data set, power level, between-study heterogeneity, within-study heterogeneity, sampling correlation, the pattern of the categories' true effect sizes, and balance of the number of studies across the levels of the covariate. The results of this study can be used by applied meta-analytic researchers who wish to conduct an \textit{a priori} power analysis for the test of a study-level categorical moderator when accounting for dependent effect sizes in a CHE+RVE model.  

